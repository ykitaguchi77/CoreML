{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/CoreML/blob/main/yolov7Conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9djSQod7j2n1",
        "outputId": "2f5324d5-2f6b-4707-9035-d03ee6e939f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 998, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 998 (delta 0), reused 0 (delta 0), pack-reused 994\u001b[K\n",
            "Receiving objects: 100% (998/998), 69.70 MiB | 35.46 MiB/s, done.\n",
            "Resolving deltas: 100% (492/492), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd yolov7/"
      ],
      "metadata": {
        "id": "mt6DCxjGkXP1",
        "outputId": "0ccc40df-d00d-4eb6-e436-e1609a91de92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ],
      "metadata": {
        "id": "GLg1y1srkchf",
        "outputId": "783c6718-73d0-472a-bbe1-324180ee7899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-17 03:11:44--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221017%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221017T031144Z&X-Amz-Expires=300&X-Amz-Signature=df5b127410adc76b4327ba765e9a9af1747f437ff526e45f8793da313b92f4dd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-10-17 03:11:44--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221017%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221017T031144Z&X-Amz-Expires=300&X-Amz-Signature=df5b127410adc76b4327ba765e9a9af1747f437ff526e45f8793da313b92f4dd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: â€˜yolov7.ptâ€™\n",
            "\n",
            "yolov7.pt           100%[===================>]  72.08M  94.5MB/s    in 0.8s    \n",
            "\n",
            "2022-10-17 03:11:45 (94.5 MB/s) - â€˜yolov7.ptâ€™ saved [75587165/75587165]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install coremltools"
      ],
      "metadata": {
        "id": "u_JqTm4Fk8TB",
        "outputId": "2ca9c9a1-9f6b-4b9d-a09e-7dd1a5b7e583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting coremltools\n",
            "  Downloading coremltools-6.0-cp37-none-manylinux1_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5 MB 20.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (3.17.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.7.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.1.0->coremltools) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools) (3.0.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools) (1.2.1)\n",
            "Installing collected packages: coremltools\n",
            "Successfully installed coremltools-6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source inference/images/pexels-vincent-rivaud-2233348.jpg\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRlxt8BSpDao",
        "outputId": "49c4f754-6773-40e1-8568-e742af328109"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='inference/images/pexels-vincent-rivaud-2233348.jpg', update=False, view_img=False, weights=['yolov7.pt'])\n",
            "YOLOR ðŸš€ v0.1-115-g072f76c torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"detect.py\", line 196, in <module>\n",
            "    detect()\n",
            "  File \"detect.py\", line 57, in detect\n",
            "    dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
            "  File \"/content/yolov7/utils/datasets.py\", line 138, in __init__\n",
            "    raise Exception(f'ERROR: {p} does not exist')\n",
            "Exception: ERROR: /content/yolov7/inference/images/pexels-vincent-rivaud-2233348.jpg does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/export.py --weight yolov7.pt"
      ],
      "metadata": {
        "id": "ZgTddBFjk9y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you use custom traned model, you can change the class labels to your own classes.You can specify as many classes as you like.\n",
        "classLabels = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "numberOfClassLabels = len(classLabels)\n",
        "outputSize = numberOfClassLabels + 5"
      ],
      "metadata": {
        "id": "AKkDtPvrD5qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run to define the decode function\n",
        "import torch\n",
        "# classLabels = [f\"label{i}\" for i in range(80)]\n",
        "numberOfClassLabels = len(classLabels)\n",
        "outputSize = numberOfClassLabels + 5\n",
        "\n",
        "#  Attention: Some models are reversed!\n",
        "reverseModel = False  \n",
        "\n",
        "strides = [8, 16, 32]\n",
        "if reverseModel:\n",
        "    strides.reverse()\n",
        "featureMapDimensions = [640 // stride for stride in strides]\n",
        "\n",
        "anchors = ([12,16, 19,36, 40,28] , [36,75, 76,55, 72,146], [142,110, 192,243, 459,401])  # Take these from the <model>.yml in yolov5\n",
        "if reverseModel:\n",
        "    anchors = anchors[::-1]\n",
        "\n",
        "anchorGrid = torch.tensor(anchors).float().view(3, -1, 1, 1, 2)\n",
        "\n",
        "def make_grid(nx, ny):\n",
        "    yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
        "    return torch.stack((xv, yv), 2).view((ny, nx, 2)).float()\n",
        "\n",
        "def addExportLayerToCoreml(builder):\n",
        "    '''\n",
        "    Adds the yolov5 export layer to the coreml model\n",
        "    '''\n",
        "    outputNames = [output.name for output in builder.spec.description.output]\n",
        "\n",
        "    for i, outputName in enumerate(outputNames):\n",
        "        # formulas: https://github.com/ultralytics/yolov5/issues/471\n",
        "        builder.add_activation(name=f\"sigmoid_{outputName}\", non_linearity=\"SIGMOID\",\n",
        "                               input_name=outputName, output_name=f\"{outputName}_sigmoid\")\n",
        "\n",
        "        ### Coordinates calculation ###\n",
        "        # input (1, 3, nC, nC, 85), output (1, 3, nC, nC, 2) -> nC = 640 / strides[i]\n",
        "        builder.add_slice(name=f\"slice_coordinates_xy_{outputName}\", input_name=f\"{outputName}_sigmoid\",\n",
        "                          output_name=f\"{outputName}_sliced_coordinates_xy\", axis=\"width\", start_index=0, end_index=2)\n",
        "        # x,y * 2\n",
        "        builder.add_elementwise(name=f\"multiply_xy_by_two_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_sliced_coordinates_xy\"], output_name=f\"{outputName}_multiplied_xy_by_two\", mode=\"MULTIPLY\", alpha=2)\n",
        "        # x,y * 2 - 0.5\n",
        "        builder.add_elementwise(name=f\"subtract_0_5_from_xy_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_multiplied_xy_by_two\"], output_name=f\"{outputName}_subtracted_0_5_from_xy\", mode=\"ADD\", alpha=-0.5)\n",
        "        grid = make_grid(\n",
        "            featureMapDimensions[i], featureMapDimensions[i]).numpy()\n",
        "        # x,y * 2 - 0.5 + grid[i]\n",
        "        builder.add_bias(name=f\"add_grid_from_xy_{outputName}\", input_name=f\"{outputName}_subtracted_0_5_from_xy\",\n",
        "                         output_name=f\"{outputName}_added_grid_xy\", b=grid, shape_bias=grid.shape)\n",
        "        # (x,y * 2 - 0.5 + grid[i]) * stride[i]\n",
        "        builder.add_elementwise(name=f\"multiply_xy_by_stride_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_added_grid_xy\"], output_name=f\"{outputName}_calculated_xy\", mode=\"MULTIPLY\", alpha=strides[i])\n",
        "\n",
        "        # input (1, 3, nC, nC, 85), output (1, 3, nC, nC, 2)\n",
        "        builder.add_slice(name=f\"slice_coordinates_wh_{outputName}\", input_name=f\"{outputName}_sigmoid\",\n",
        "                          output_name=f\"{outputName}_sliced_coordinates_wh\", axis=\"width\", start_index=2, end_index=4)\n",
        "        # w,h * 2\n",
        "        builder.add_elementwise(name=f\"multiply_wh_by_two_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_sliced_coordinates_wh\"], output_name=f\"{outputName}_multiplied_wh_by_two\", mode=\"MULTIPLY\", alpha=2)\n",
        "        # (w,h * 2) ** 2\n",
        "        builder.add_unary(name=f\"power_wh_{outputName}\", input_name=f\"{outputName}_multiplied_wh_by_two\",\n",
        "                          output_name=f\"{outputName}_power_wh\", mode=\"power\", alpha=2)\n",
        "        # (w,h * 2) ** 2 * anchor_grid[i]\n",
        "        anchor = anchorGrid[i].expand(-1, featureMapDimensions[i],\n",
        "                                      featureMapDimensions[i], -1).numpy()\n",
        "        builder.add_load_constant_nd(\n",
        "            name=f\"anchors_{outputName}\", output_name=f\"{outputName}_anchors\", constant_value=anchor, shape=anchor.shape)\n",
        "        builder.add_elementwise(name=f\"multiply_wh_with_achors_{outputName}\", input_names=[\n",
        "                                f\"{outputName}_power_wh\", f\"{outputName}_anchors\"], output_name=f\"{outputName}_calculated_wh\", mode=\"MULTIPLY\")\n",
        "\n",
        "        builder.add_concat_nd(name=f\"concat_coordinates_{outputName}\", input_names=[\n",
        "                              f\"{outputName}_calculated_xy\", f\"{outputName}_calculated_wh\"], output_name=f\"{outputName}_raw_coordinates\", axis=-1)\n",
        "        builder.add_scale(name=f\"normalize_coordinates_{outputName}\", input_name=f\"{outputName}_raw_coordinates\",\n",
        "                          output_name=f\"{outputName}_raw_normalized_coordinates\", W=torch.tensor([1 / 640]).numpy(), b=0, has_bias=False)\n",
        "\n",
        "        ### Confidence calculation ###\n",
        "        builder.add_slice(name=f\"slice_object_confidence_{outputName}\", input_name=f\"{outputName}_sigmoid\",\n",
        "                          output_name=f\"{outputName}_object_confidence\", axis=\"width\", start_index=4, end_index=5)\n",
        "        builder.add_slice(name=f\"slice_label_confidence_{outputName}\", input_name=f\"{outputName}_sigmoid\",\n",
        "                          output_name=f\"{outputName}_label_confidence\", axis=\"width\", start_index=5, end_index=0)\n",
        "        # confidence = object_confidence * label_confidence\n",
        "        builder.add_multiply_broadcastable(name=f\"multiply_object_label_confidence_{outputName}\", input_names=[\n",
        "                                           f\"{outputName}_label_confidence\", f\"{outputName}_object_confidence\"], output_name=f\"{outputName}_raw_confidence\")\n",
        "\n",
        "        # input: (1, 3, nC, nC, 85), output: (3 * nc^2, 85)\n",
        "        builder.add_flatten_to_2d(\n",
        "            name=f\"flatten_confidence_{outputName}\", input_name=f\"{outputName}_raw_confidence\", output_name=f\"{outputName}_flatten_raw_confidence\", axis=-1)\n",
        "        builder.add_flatten_to_2d(\n",
        "            name=f\"flatten_coordinates_{outputName}\", input_name=f\"{outputName}_raw_normalized_coordinates\", output_name=f\"{outputName}_flatten_raw_coordinates\", axis=-1)\n",
        "\n",
        "    builder.add_concat_nd(name=\"concat_confidence\", input_names=[\n",
        "                          f\"{outputName}_flatten_raw_confidence\" for outputName in outputNames], output_name=\"raw_confidence\", axis=-2)\n",
        "    builder.add_concat_nd(name=\"concat_coordinates\", input_names=[\n",
        "                          f\"{outputName}_flatten_raw_coordinates\" for outputName in outputNames], output_name=\"raw_coordinates\", axis=-2)\n",
        "\n",
        "    builder.set_output(output_names=[\"raw_confidence\", \"raw_coordinates\"], output_dims=[\n",
        "                       (25200, numberOfClassLabels), (25200, 4)])"
      ],
      "metadata": {
        "id": "Hpigyc_5Fbri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run to define the NMS function\n",
        "\n",
        "def createNmsModelSpec(nnSpec):\n",
        "    '''\n",
        "    Create a coreml model with nms to filter the results of the model\n",
        "    '''\n",
        "    nmsSpec = ct.proto.Model_pb2.Model()\n",
        "    nmsSpec.specificationVersion = 4\n",
        "\n",
        "    # Define input and outputs of the model\n",
        "    for i in range(2):\n",
        "        nnOutput = nnSpec.description.output[i].SerializeToString()\n",
        "\n",
        "        nmsSpec.description.input.add()\n",
        "        nmsSpec.description.input[i].ParseFromString(nnOutput)\n",
        "\n",
        "        nmsSpec.description.output.add()\n",
        "        nmsSpec.description.output[i].ParseFromString(nnOutput)\n",
        "\n",
        "    nmsSpec.description.output[0].name = \"confidence\"\n",
        "    nmsSpec.description.output[1].name = \"coordinates\"\n",
        "\n",
        "    # Define output shape of the model\n",
        "    outputSizes = [numberOfClassLabels, 4]\n",
        "    for i in range(len(outputSizes)):\n",
        "        maType = nmsSpec.description.output[i].type.multiArrayType\n",
        "        # First dimension of both output is the number of boxes, which should be flexible\n",
        "        maType.shapeRange.sizeRanges.add()\n",
        "        maType.shapeRange.sizeRanges[0].lowerBound = 0\n",
        "        maType.shapeRange.sizeRanges[0].upperBound = -1\n",
        "        # Second dimension is fixed, for \"confidence\" it's the number of classes, for coordinates it's position (x, y) and size (w, h)\n",
        "        maType.shapeRange.sizeRanges.add()\n",
        "        maType.shapeRange.sizeRanges[1].lowerBound = outputSizes[i]\n",
        "        maType.shapeRange.sizeRanges[1].upperBound = outputSizes[i]\n",
        "        del maType.shape[:]\n",
        "\n",
        "    # Define the model type non maximum supression\n",
        "    nms = nmsSpec.nonMaximumSuppression\n",
        "    nms.confidenceInputFeatureName = \"raw_confidence\"\n",
        "    nms.coordinatesInputFeatureName = \"raw_coordinates\"\n",
        "    nms.confidenceOutputFeatureName = \"confidence\"\n",
        "    nms.coordinatesOutputFeatureName = \"coordinates\"\n",
        "    nms.iouThresholdInputFeatureName = \"iouThreshold\"\n",
        "    nms.confidenceThresholdInputFeatureName = \"confidenceThreshold\"\n",
        "    # Some good default values for the two additional inputs, can be overwritten when using the model\n",
        "    nms.iouThreshold = 0.6\n",
        "    nms.confidenceThreshold = 0.4\n",
        "    nms.stringClassLabels.vector.extend(classLabels)\n",
        "\n",
        "    return nmsSpec\n"
      ],
      "metadata": {
        "id": "g9rgzl0_DrxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run to combine the model added decode and the NMS.\n",
        "def combineModelsAndExport(builderSpec, nmsSpec, fileName, quantize=False):\n",
        "    '''\n",
        "    Combines the coreml model with export logic and the nms to one final model. Optionally save with different quantization (32, 16, 8) (Works only if on Mac Os)\n",
        "    '''\n",
        "    try:\n",
        "        print(f'Combine CoreMl model with nms and export model')\n",
        "        # Combine models to a single one\n",
        "        pipeline = ct.models.pipeline.Pipeline(input_features=[(\"image\", ct.models.datatypes.Array(3, 460, 460)),\n",
        "                                                               (\"iouThreshold\", ct.models.datatypes.Double(\n",
        "                                                               )),\n",
        "                                                               (\"confidenceThreshold\", ct.models.datatypes.Double())], output_features=[\"confidence\", \"coordinates\"])\n",
        "\n",
        "        # Required version (>= ios13) in order for mns to work\n",
        "        pipeline.spec.specificationVersion = 4\n",
        "\n",
        "        pipeline.add_model(builderSpec)\n",
        "        pipeline.add_model(nmsSpec)\n",
        "\n",
        "        pipeline.spec.description.input[0].ParseFromString(\n",
        "            builderSpec.description.input[0].SerializeToString())\n",
        "        pipeline.spec.description.output[0].ParseFromString(\n",
        "            nmsSpec.description.output[0].SerializeToString())\n",
        "        pipeline.spec.description.output[1].ParseFromString(\n",
        "            nmsSpec.description.output[1].SerializeToString())\n",
        "\n",
        "        # Metadata for the modelâ€š\n",
        "        pipeline.spec.description.input[\n",
        "            1].shortDescription = \"(optional) IOU Threshold override (Default: 0.6)\"\n",
        "        pipeline.spec.description.input[\n",
        "            2].shortDescription = \"(optional) Confidence Threshold override (Default: 0.4)\"\n",
        "        pipeline.spec.description.output[0].shortDescription = u\"Boxes \\xd7 Class confidence\"\n",
        "        pipeline.spec.description.output[\n",
        "            1].shortDescription = u\"Boxes \\xd7 [x, y, width, height] (relative to image size)\"\n",
        "        pipeline.spec.description.metadata.versionString = \"1.0\"\n",
        "        pipeline.spec.description.metadata.shortDescription = \"yolov5\"\n",
        "        pipeline.spec.description.metadata.author = \"Leon De Andrade\"\n",
        "        pipeline.spec.description.metadata.license = \"\"\n",
        "\n",
        "        model = ct.models.MLModel(pipeline.spec)\n",
        "        model.save(fileName)\n",
        "\n",
        "        if quantize:\n",
        "            fileName16 = fileName.replace(\".mlmodel\", \"_16.mlmodel\")\n",
        "            modelFp16 = ct.models.neural_network.quantization_utils.quantize_weights(\n",
        "                model, nbits=16)\n",
        "            modelFp16.save(fileName16)\n",
        "\n",
        "            fileName8 = fileName.replace(\".mlmodel\", \"_8.mlmodel\")\n",
        "            modelFp8 = ct.models.neural_network.quantization_utils.quantize_weights(\n",
        "                model, nbits=8)\n",
        "            modelFp8.save(fileName8)\n",
        "\n",
        "        print(f'CoreML export success, saved as {fileName}')\n",
        "    except Exception as e:\n",
        "        print(f'CoreML export failure: {e}')"
      ],
      "metadata": {
        "id": "gq8rtvsbEDYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You need specify the path to your model that converted and saved in the same folder of your weight file.\n",
        "import coremltools as ct\n",
        "mlmodel = ct.models.MLModel(\"yolov7.mlmodel\")"
      ],
      "metadata": {
        "id": "eUthrL2h-CEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run to get the mlmodel spec.\n",
        "spec = mlmodel.get_spec()\n",
        "builder = ct.models.neural_network.NeuralNetworkBuilder(spec=spec)\n",
        "spec.description"
      ],
      "metadata": {
        "id": "DRZi7EcuxCTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17316ea0-ae46-45e7-d245-9a69e6a5f364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "input {\n",
              "  name: \"image\"\n",
              "  type {\n",
              "    imageType {\n",
              "      width: 640\n",
              "      height: 640\n",
              "      colorSpace: RGB\n",
              "    }\n",
              "  }\n",
              "}\n",
              "output {\n",
              "  name: \"var_1553\"\n",
              "  type {\n",
              "    multiArrayType {\n",
              "      dataType: FLOAT32\n",
              "    }\n",
              "  }\n",
              "}\n",
              "output {\n",
              "  name: \"var_1568\"\n",
              "  type {\n",
              "    multiArrayType {\n",
              "      dataType: FLOAT32\n",
              "    }\n",
              "  }\n",
              "}\n",
              "output {\n",
              "  name: \"var_1583\"\n",
              "  type {\n",
              "    multiArrayType {\n",
              "      dataType: FLOAT32\n",
              "    }\n",
              "  }\n",
              "}\n",
              "metadata {\n",
              "  userDefined {\n",
              "    key: \"com.github.apple.coremltools.source\"\n",
              "    value: \"torch==1.11.0+cu113\"\n",
              "  }\n",
              "  userDefined {\n",
              "    key: \"com.github.apple.coremltools.version\"\n",
              "    value: \"5.2.0\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run the functions to add decode layer and NMS to the model.\n",
        "addExportLayerToCoreml(builder)\n",
        "nmsSpec = createNmsModelSpec(builder.spec)\n",
        "combineModelsAndExport(builder.spec, nmsSpec, f\"yolov7.mlmodel\") # The model will be saved in this path."
      ],
      "metadata": {
        "id": "3x5Mbli7Dk0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78da308-32ac-4bf8-864b-b609339596e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combine CoreMl model with nms and export model\n",
            "CoreML export success, saved as /content/drive/MyDrive/yolov7.mlmodel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUx2ftrZrAbs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}